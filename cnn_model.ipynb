{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
                "import numpy as np\n",
                "import os\n",
                "import cv2\n",
                "\n",
                "# Bu kütüphaneler, görüntüleri yükleme, dönüştürme ve veri artırma işlemleri için kullanılır.\n",
                "\n",
                "# ImageDataGenerator, çeşitli veri artırma tekniklerini (dönüşüm, çevirme, kırpma, vb.) kullanarak\n",
                "# görüntüleri dönüştürüp model için daha çeşitli ve geniş veri setleri yaratır.\n",
                "\n",
                "# img_to_array fonksiyonu, bir görüntüyü NumPy dizisine dönüştürür.\n",
                "# load_img fonksiyonu ise, belirtilen yolu kullanarak bir görüntü dosyasını yükler.\n",
                "\n",
                "# cv2, OpenCV kütüphanesidir ve görüntü işleme, analiz etme, dönüştürme gibi çeşitli işlemler için kullanılır.\n",
                "#Bu kütüphaneler genellikle derin öğrenme projelerinde kullanılır ve bir modelin eğitilmesi veya test edilmesi sırasında görsel veriler üzerinde çeşitli işlemler yapmanıza olanak tanır."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "inputBasePath = r\"C:\\Users\\mbaki\\OneDrive\\Masaüstü\\Okul2.dönem\\yapay zeka\\images\"\n",
                "outputBasePath = r\"C:\\Users\\mbaki\\OneDrive\\Masaüstü\\Okul2.dönem\\yapay zeka\\processed_images\"\n",
                "os.makedirs(outputBasePath, exist_ok=True)\n",
                "\n",
                "image_width = 224\n",
                "image_height = 224\n",
                "classes = ['cat', 'dog']\n",
                "#Bu yapı, görüntü verilerinin işlenmesi, sınıflandırılması ve modelin doğru bir şekilde eğitilmesi için gerekli başlangıç parametrelerini belirler."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = []\n",
                "Y = []\n",
                "\n",
                "# Resimleri oku ve numpy array'e dönüştür\n",
                "for class1 in classes:\n",
                "    class_path = os.path.join(inputBasePath, class1)\n",
                "    for img_name in os.listdir(class_path):\n",
                "        img_path = os.path.join(class_path, img_name)\n",
                "        img = load_img(img_path, target_size=(image_width, image_height))\n",
                "        img_array = img_to_array(img) / 255.0  # Normalize et\n",
                "        X.append(img_array)\n",
                "        Y.append(classes.index(class1))\n",
                "# işlenmiş görüntülerin numpy dizilerini depolayacak ve her bir resme ait etiketleri depolayacak. Etiketler, sınıf adlarının indeksleri olacaktır"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Veriyi numpy array'e çevir\n",
                "X = np.array(X)\n",
                "Y = np.array(Y)\n",
                "# X ve Y listesinde tutulan tüm görüntü verilerini, NumPy dizisine dönüştürür."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modeli oluştur\n",
                "model = tf.keras.Sequential([\n",
                "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)),\n",
                "    tf.keras.layers.MaxPooling2D(2, 2),\n",
                "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
                "    tf.keras.layers.MaxPooling2D(2, 2),\n",
                "    tf.keras.layers.Flatten(),\n",
                "    tf.keras.layers.Dense(128, activation='relu'),\n",
                "    tf.keras.layers.Dense(len(classes), activation='softmax')\n",
                "])\n",
                "#tf.keras.Sequential([...]): Modelin sıralı bir yapıda olduğunu belirtir, yani katmanlar sırayla birleştirilir.\n",
                "# Max-pooling katmanı, görüntünün boyutunu küçültür ve öne çıkan özellikleri daha belirgin hale getirir. 2x2 boyutundaki pencerede her seferinde en büyük değeri seçer.\n",
                "#Conv2D(64, (3, 3), activation='relu'): İkinci konvolüsyonel katman, 64 adet 3x3 boyutunda filtre kullanır. Bu katman daha fazla özellik çıkarımı yapar.\n",
                "#İkinci max-pooling katmanı, önceki adımda olduğu gibi, boyutları küçültür ve öne çıkan özellikleri korur.\n",
                "#Flatten(): Bu katman, 2D çıktıyı tek bir vektöre dönüştürür, böylece tam bağlantılı katmanlara aktarılabilir.\n",
                "#Dense(128, activation='relu'): Bu katman, 128 nöron içerir ve ReLU aktivasyonu kullanarak doğrusal olmayan ilişkiler öğrenmeye çalışır.\n",
                "#Son katman, sınıf sayısına (len(classes)) göre çıkış yapar. Softmax aktivasyonu, her sınıfa ait olasılıkları verir ve sınıflandırma görevinde her sınıfın en yüksek olasılığını seçer.\n",
                "\n",
                "#Model, bir görüntü verisini alır ve ilk konvolüsyon katmanında, görüntünün temel özelliklerini (kenarlar, renkler vb.) çıkarır.\n",
                "\n",
                "#MaxPooling katmanları, bu bilgiyi daha küçük boyutlarda ama önemli olan özelliklerle temsil eder.\n",
                "\n",
                "#Flatten katmanı, bu 2D veriyi 1D hale getirir ve Dense katmanlarına gönderir.\n",
                "\n",
                "#Son olarak, Dense katmanları bu bilgiyi işleyerek hangi sınıfa ait olduğunu tahmin eder\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modeli derle\n",
                "model.compile(optimizer='adam',\n",
                "              loss='sparse_categorical_crossentropy',\n",
                "              metrics=['accuracy'])\n",
                "#Bu derleme işlemi, modelin eğitim sürecini başlatmak için hazır hale gelmesini sağlar ve belirlenen kayıp fonksiyonu ile modelin çıktıları arasındaki farkı minimize etmeye çalışır."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/5\n",
                        "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 442ms/step - accuracy: 0.4776 - loss: 5.0492 - val_accuracy: 0.0000e+00 - val_loss: 0.8200\n",
                        "Epoch 2/5\n",
                        "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399ms/step - accuracy: 0.5978 - loss: 0.6719 - val_accuracy: 0.0000e+00 - val_loss: 1.2265\n",
                        "Epoch 3/5\n",
                        "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - accuracy: 0.5852 - loss: 0.7037 - val_accuracy: 0.2449 - val_loss: 0.8523\n",
                        "Epoch 4/5\n",
                        "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.6454 - loss: 0.6069 - val_accuracy: 0.5306 - val_loss: 0.6345\n",
                        "Epoch 5/5\n",
                        "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - accuracy: 0.7672 - loss: 0.4918 - val_accuracy: 1.0000 - val_loss: 0.1795\n"
                    ]
                }
            ],
            "source": [
                "# Modeli eğit\n",
                "history = model.fit(X, Y, epochs=5, validation_split=0.2)\n",
                "#Bu kod, modelin eğitim sürecini başlatır ve her epoch sonunda doğruluk ve kayıp gibi metriklerin izlenmesine olanak tanır. Bu metrikler, modelin performansını değerlendirmenize yardımcı olur."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Eğitim Doğruluğu: 0.7897\n",
                        "Doğrulama Doğruluğu: 1.0000\n"
                    ]
                }
            ],
            "source": [
                "# Modelin doğruluk değerlerini yazdır\n",
                "train_acc = history.history['accuracy'][-1]\n",
                "val_acc = history.history['val_accuracy'][-1]\n",
                "print(f\"Eğitim Doğruluğu: {train_acc:.4f}\")\n",
                "print(f\"Doğrulama Doğruluğu: {val_acc:.4f}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
